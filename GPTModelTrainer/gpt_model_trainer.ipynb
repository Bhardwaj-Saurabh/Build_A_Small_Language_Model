{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "54446776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8c68bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f0467ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-map the training dataset file into numpy array (uint32).\n",
    "# train_data = np.memmap('../preprocess_data/train.bin', dtype=np.uint32, mode='r')\n",
    "\n",
    "# # Memory-map the validation dataset file.\n",
    "# val_data = np.memmap('../preprocess_data/validation.bin', dtype=np.uint32, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "51fcbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "033d0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "45e11666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b091845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.0,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84072f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataloader(train_data,\n",
    "                          batch_size=2,\n",
    "                          max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                          stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "val_loader = dataloader(val_data,\n",
    "                        batch_size=2,\n",
    "                        max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                        stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                        shuffle=False,\n",
    "                        drop_last=True,\n",
    "                        num_workers=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee43af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, n_heads, context_length, drop_rate=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % n_heads == 0, \"d_out must be divisible by n_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_out // n_heads\n",
    "        \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "        self.attn_drop = nn.Dropout(drop_rate)\n",
    "        self.proj_out = nn.Linear(d_out, d_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)    \n",
    "        \n",
    "        queries = queries.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        keys = keys.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)   \n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        attn_scores.masked_fill_(\n",
    "            self.mask.bool()[:T, :T], -torch.inf\n",
    "        )\n",
    "        attn_scores = attn_scores / (keys.shape[-1] ** 0.5)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.attn_drop(attn_weights)\n",
    "        \n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(B, T, self.d_out)\n",
    "        \n",
    "        context_vec = self.proj_out(context_vec)\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fc7581ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        \n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * x_norm + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "201db087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bbe5bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7844b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.mha = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            n_heads=cfg[\"n_heads\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            drop_rate=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ln2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.drop = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.drop(self.mha(self.ln1(x)))\n",
    "        x = x + self.drop(self.ff(self.ln2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "912cbd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emd = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        self.drop = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            * [TranformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        \n",
    "        self.ln_f = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        self.out_proj = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        B, T = input_ids.shape\n",
    "        \n",
    "        tok_emb = self.tok_emb(input_ids)\n",
    "        pos_emb = self.pos_emd(torch.arange(T, device=input_ids.device))\n",
    "        \n",
    "        x = self.drop(tok_emb + pos_emb)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        \n",
    "        logits = self.out_proj(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "39fc68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "74962a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "671aaafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_context = \"Hello, I am\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9d5ac7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 34239, 28245, 43327, 20977, 33555, 34997]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval() # disable dropout\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6dfac3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I amgres Baylorjumpâ€‘ Manor Procedure\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb162b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5541d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9f19d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c291ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calculate_loss(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dca1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.927, Val loss 10.045\n",
      "Ep 1 (Step 000005): Train loss 8.172, Val loss 8.470\n",
      "Ep 2 (Step 000010): Train loss 6.630, Val loss 7.096\n",
      "Ep 2 (Step 000015): Train loss 5.986, Val loss 6.567\n",
      "Ep 3 (Step 000020): Train loss 5.458, Val loss 6.436\n",
      "Ep 3 (Step 000025): Train loss 5.347, Val loss 6.402\n",
      "Ep 4 (Step 000030): Train loss 5.306, Val loss 6.499\n",
      "Ep 4 (Step 000035): Train loss 5.017, Val loss 6.352\n",
      "Ep 5 (Step 000040): Train loss 4.357, Val loss 6.339\n",
      "Ep 6 (Step 000045): Train loss 4.165, Val loss 6.273\n",
      "Ep 6 (Step 000050): Train loss 3.706, Val loss 6.260\n",
      "Ep 7 (Step 000055): Train loss 3.679, Val loss 6.240\n",
      "Ep 7 (Step 000060): Train loss 2.895, Val loss 6.119\n",
      "Ep 8 (Step 000065): Train loss 2.402, Val loss 6.191\n",
      "Ep 8 (Step 000070): Train loss 2.037, Val loss 6.202\n",
      "Ep 9 (Step 000075): Train loss 1.663, Val loss 6.192\n",
      "Ep 9 (Step 000080): Train loss 1.272, Val loss 6.282\n",
      "Ep 10 (Step 000085): Train loss 0.946, Val loss 6.318\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "07a919e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4bacaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest logits value\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a8bf023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ed6f13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2a1f0cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861ab03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d19268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684c0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3ade1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-a-small-language-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
